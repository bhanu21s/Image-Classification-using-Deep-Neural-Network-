# -*- coding: utf-8 -*-
"""Copy_of_vgg16_final (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OCso3T_w3EX_NMMZ2WE-chkQH67lvjru
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
!pip install torchvision
import torchvision
import matplotlib.pyplot as plt

device = "cuda" if torch.cuda.is_available() else "cpu"
kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {}

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard

"""Util
---
"""

def matplotlib_imshow(img, one_channel=False):
    if one_channel:
        img = img.mean(dim=0)
    img = img / 2 + 0.5     # unnormalize
    npimg = img.cpu().data.numpy()
    if one_channel:
        plt.imshow(npimg, cmap="Greys")
    else:
        plt.imshow(np.transpose(npimg, (1, 2, 0)))

# helper functions

def images_to_probs(net, images):
    '''
    Generates predictions and corresponding probabilities from a trained
    network and a list of images
    '''
    output = net(images)
    # convert output probabilities to predicted class
    _, preds_tensor = torch.max(output[1], 1)
    preds = np.squeeze(preds_tensor.cpu().data.numpy())
    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output[0])]


def plot_classes_preds(net, images, labels):
    '''
    Generates matplotlib Figure using a trained network, along with images
    and labels from a batch, that shows the network's top prediction along
    with its probability, alongside the actual label, coloring this
    information based on whether the prediction was correct or not.
    Uses the "images_to_probs" function.
    '''
    classes = ('0' , '1' , '2' , '3' , '4' , '5', '6' , '7', ' 8' , '9')
    preds, probs = images_to_probs(net, images)
    # plot the images in the batch, along with predicted and true labels
    fig = plt.figure(figsize=(12, 48))
    for idx in np.arange(4):
        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])
        matplotlib_imshow(images[idx], one_channel=True)
        ax.set_title("{0}, {1:.1f}%\n(label: {2})".format(
            classes[preds[idx]],
            probs[idx] * 100.0,
            classes[labels[idx]]),
                    color=("green" if preds[idx]==labels[idx].item() else "red"))
    return fig

from torch.utils.tensorboard import SummaryWriter

# default `log_dir` is "runs" - we'll be more specific here
writer = SummaryWriter('runs/vgg_mnist_experiment_1')

n_epochs = 3
batch_size_train = 64
batch_size_test = 1000
learning_rate = 0.01
momentum = 0.5
log_interval = 10

random_seed = 1
torch.backends.cudnn.enabled = False
torch.manual_seed(random_seed)

# input = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2)

# print(input.shape)
# m = nn.UpsamplingNearest2d(scale_factor=2)
# m(input).shape

"""Data
---
"""

from torchvision.transforms import transforms
from torchvision.transforms.functional import resize
# transforms_list =   transform=torchvision.transforms.Compose([                
#                                                               torchvision.transforms.ToTensor(),                                                            
#                                                               transforms.Lambda(lambda x: x.repeat(3, 1, 1)),                    
#                                                               transforms.Lambda(lambda x: nn.UpsamplingNearest2d(scale_factor=8)(x.view(1,3, 28, 28))[0]),
#                                                               torchvision.transforms.Normalize( (0.1307,), (0.3081,)),  
#                                                         ])

transforms_list =   transform=torchvision.transforms.Compose([                
                                                              torchvision.transforms.ToTensor(),                  
                                                              transforms.Lambda(lambda x: nn.UpsamplingNearest2d(scale_factor=8)(x.view(1,1, 28, 28))[0]),
                                                              torchvision.transforms.Normalize( (0.1307,), (0.3081,)),  
                                                        ])

train_dataset =   torchvision.datasets.MNIST('/files/', train=True, download=True, transform=transforms_list)

train_data , val_data = torch.utils.data.random_split(train_dataset, [52000, 8000],generator=torch.Generator().manual_seed(42))
train_loader = torch.utils.data.DataLoader(train_data,  batch_size=batch_size_train, **kwargs)
val_loader = torch.utils.data.DataLoader(val_data,  batch_size=batch_size_train, **kwargs)

test_loader = torch.utils.data.DataLoader(
  torchvision.datasets.MNIST('files/', train=False, download=True , transform = transforms_list),
  batch_size=batch_size_test, **kwargs)

# examples = enumerate(train_loader)
# batch_idx, (example_data, example_targets) = next(examples)
# example_data.shape , example_targets.shape

# get some random training images
dataiter = iter(train_loader)
images, labels = dataiter.next()

# create grid of images
img_grid = torchvision.utils.make_grid(images)

# show images
matplotlib_imshow(img_grid, one_channel=True)

# write to tensorboard
writer.add_image('four_mnist_images', img_grid)

"""tensorboard run
---
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir=runs

# import matplotlib.pyplot as plt

# fig = plt.figure()
# for i in range(6):
#   plt.subplot(2,3,i+1)
#   plt.tight_layout()
#   plt.imshow(example_data[i][0], cmap='gray', interpolation='none')
#   plt.title("Ground Truth: {}".format(example_targets[i]))
#   plt.xticks([])
#   plt.yticks([])
# fig

"""vgg16
---
"""

class VGG16(nn.Module):
  def __init__(self):
    super(VGG16, self).__init__()
    self.conv1 = torch.nn.Conv2d(kernel_size=3, in_channels= 1, out_channels=64, padding= 'same')
    self.conv2 = torch.nn.Conv2d(kernel_size=3, in_channels= 64, out_channels=64, padding = 'same')

    self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)
    self.conv3 =  torch.nn.Conv2d(kernel_size=3, in_channels=64, out_channels=128, padding= 'same')
    self.conv4 =  torch.nn.Conv2d(kernel_size=3, in_channels=128, out_channels=128, padding= 'same')

    self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
    self.conv5 =  torch.nn.Conv2d(kernel_size=3, in_channels=128, out_channels=256, padding= 'same')
    self.conv6 =  torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=256, padding= 'same')
    self.conv7 =  torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=256, padding= 'same')

    self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)
    self.conv8 =  torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=512, padding= 'same')
    self.conv9 =  torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512, padding= 'same')
    self.conv10 =  torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512, padding= 'same')

    self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)
    self.conv11 =  torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512, padding= 'same')
    self.conv12 =  torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512, padding= 'same')
    self.conv13 =  torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512, padding= 'same')

    self.maxpool5 = nn.MaxPool2d(kernel_size=2, stride=2)
    self.fc1= nn.Linear(in_features = 25088, out_features = 4096)
    self.fc2 = nn.Linear(in_features = 4096, out_features = 4096)
    self.fc3 = nn.Linear(in_features = 4096, out_features= 10)
    
  def forward(self, x):
    conv_out = self.conv1(x)
    x = nn.functional.relu(conv_out)
    conv_out = self.conv2(x)
    x = nn.functional.relu(conv_out)
    x = self.maxpool1(x)

    conv_out = self.conv3(x)
    x = nn.functional.relu(conv_out)
    conv_out = self.conv4(x)
    x = nn.functional.relu(conv_out)
    x = self.maxpool2(x)

    conv_out = self.conv5(x)
    x = nn.functional.relu(conv_out)
    conv_out = self.conv6(x)
    x = nn.functional.relu(conv_out)
    conv_out = self.conv7(x)
    x = nn.functional.relu(conv_out)
    x = self.maxpool3(x)

    conv_out = self.conv8(x)
    x = nn.functional.relu(conv_out)
    conv_out = self.conv9(x)
    x = nn.functional.relu(conv_out)
    conv_out = self.conv10(x)
    x = nn.functional.relu(conv_out)
    x = self.maxpool4(x)

    conv_out = self.conv11(x)
    x = nn.functional.relu(conv_out)
    conv_out = self.conv12(x)
    x = nn.functional.relu(conv_out)
    conv_out = self.conv13(x)
    x = nn.functional.relu(conv_out)
    x = self.maxpool5(x)

    x = x.reshape(x.shape[0], -1)
    x = F.relu(self.fc1(x))
    x = F.dropout(x, 0.5) 
    x = F.relu(self.fc2(x))
    x = F.dropout(x, 0.5)
    logits  = self.fc3(x)
    probs = F.softmax(logits , dim=1)
    return logits ,probs

from torchsummary import summary
model = VGG16() #to compile the model
#model = model.to(device=device) #to send the model for training on either cuda or cpu
print(model)

writer.add_graph(model, images)

model = model.to(device=device) #to send the model for training on either cuda or cpu
summary(model,(1, 224, 224))

# examples = enumerate(train_loader)
# batch_idx, (example_data, example_targets) = next(examples)
# example_data.shape , example_targets.shape

## Loss and optimizer
from torch.optim.lr_scheduler import ReduceLROnPlateau
learning_rate = 1e-4 #I picked this because it seems to be the most used by experts
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate) #Adam seems to be the most popular for deep learning
scheduler = ReduceLROnPlateau(optimizer, 'min')

"""train
---
"""

def compute_accuracy(model, data_loader):
    model.eval()
    correct_pred, num_examples = 0, 0
    for i, (features, targets) in enumerate(data_loader):
            
        features = features.to(device)
        targets = targets.to(device)

        logits, probas = model(features)
        _, predicted_labels = torch.max(probas, 1)
        num_examples += targets.size(0)
        correct_pred += (predicted_labels == targets).sum()
    return correct_pred.float()/num_examples * 100


def compute_epoch_loss(model, data_loader):
    model.eval()
    curr_loss, num_examples = 0., 0
    with torch.no_grad():
        for features, targets in data_loader:
            features = features.to(device)
            targets = targets.to(device)
            logits, probas = model(features)
            loss = F.cross_entropy(logits, targets, reduction='sum')
            num_examples += targets.size(0)
            curr_loss += loss

        curr_loss = curr_loss / num_examples
        return curr_loss

# Commented out IPython magic to ensure Python compatibility.
import time
import numpy as np
start_time = time.time()
running_loss = 0.0
num_epochs = 10
for epoch in range(num_epochs):
    
    model.train()
    for batch_idx, (images, labels) in enumerate(train_loader):
        
        images = images.to(device)
        labels = labels.to(device)
            
        ### FORWARD AND BACK PROP
        model = model.to(device)
        logits, probas = model(images)
        cost = F.cross_entropy(logits, labels)
        optimizer.zero_grad()
        
        cost.backward()
        
        ### UPDATE MODEL PARAMETERS
        optimizer.step()

        running_loss += cost.item()
        if batch_idx % 100 == 1:    # every 1000 mini-batches...

            # ...log the running loss
            writer.add_scalar('training loss',
                            running_loss / 1000,
                            epoch * len(train_loader) + batch_idx)

            # ...log a Matplotlib Figure showing the model's predictions on a
            # random mini-batch
            writer.add_figure('predictions vs. actuals',
                            plot_classes_preds(model, images, labels),
                            global_step=epoch * len(train_loader) + batch_idx)
            running_loss = 0.0

        ### LOGGING
        if not batch_idx % 100:
            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' 
#                    %(epoch+1, num_epochs, batch_idx, 
                     len(train_loader), cost))
            

    model.eval()
    with torch.set_grad_enabled(False): # save memory during inference
        
        print('Epoch: %03d/%03d | Train: %.3f%% |  Loss: %.3f' % (
              epoch+1, num_epochs, 
              compute_accuracy(model, train_loader),
              compute_epoch_loss(model, train_loader)))
        val_loss = compute_epoch_loss(model, val_loader)
        print('Epoch: %03d/%03d | Validation: %.3f%% |  Loss: %.3f' % (
              epoch+1, num_epochs, 
              compute_accuracy(model, val_loader),
              val_loss))   
        scheduler.step(val_loss) 


    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))
    
print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))

